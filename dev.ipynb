{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook is intended to answer my question: \"which day of the week is the best day to buy Bitcoin in a bear market?\" \n",
    "\n",
    "To do this the notebook is split into four parts\n",
    "1. Download the candlestick data for BTC-USD\n",
    "2. Inspect the data for potential issues\n",
    "3. Process the data working out which day of the week is best\n",
    "4. Plot the results\n",
    "\n",
    "This working could easily be extended to look at which day of the month is best as future work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = Cryptocurrencies().find_crypto_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[pairs['id'].str.contains('BTC') * pairs['id'].str.contains('USD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Historic_Crypto import Cryptocurrencies, HistoricalData\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Historical BTC-USD Candlestick Data\n",
    "In my personal opinion - which is all that matters to me as this is a personl repo :P - I just want to look at the most recent two crypto market cycles starting from around the beginning of 2017 until today.\n",
    "\n",
    "In the past I've used the Binance API to pull their data sets through however this requries setting up an API key. Thankfully now more packages have been developed I found the Historic_Crypto package which can be used without needing an API key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data =  HistoricalData(\n",
    "        ticker = \"BTC-USD\",\n",
    "        granularity = (60 * 60 * 24), # 1 hour in seconds\n",
    "        start_date = \"2017-01-01-00-00\",\n",
    "        end_date = \"2022-06-25-00-00\"\n",
    "    ).retrieve_data();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like no missing values in any of the columns which is excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = processed_data.index.to_list()\n",
    "test0 = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0.day_name()\n",
    "test0.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['avg'] = processed_data[['low','high','open','close']].mean(axis=1)\n",
    "processed_data['1w_sma'] = processed_data['close'].rolling(window = 7 ).mean()\n",
    "processed_data['20w_sma'] = processed_data['close'].rolling(window = 7 * 20).mean()\n",
    "processed_data['year'] = [date.year for date in  processed_data.index.to_list()]\n",
    "processed_data['market'] = np.where(processed_data['1w_sma'] < processed_data['20w_sma'], \"bear\",\"bull\")\n",
    "processed_data['day_of_week'] = [date.day_name() for date in  processed_data.index.to_list()]\n",
    "processed_data['week_of_year'] = [date.weekofyear for date in  processed_data.index.to_list()]\n",
    "processed_data['week_of_year'] = [date.weekofyear for date in  processed_data.index.to_list()]\n",
    "processed_data['year_week_of_year'] = processed_data['year'].astype('str') + \"_\" + processed_data['week_of_year'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data[8:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_data = processed_data[processed_data['market'] == 'bear'][['day_of_week','year_week_of_year','avg']]\n",
    "bear_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_avg_per_week = bear_data.groupby('year_week_of_year').min('avg')\n",
    "min_avg_per_week.rename(columns = {\"avg\":\"min_weekly\"},inplace=True)\n",
    "min_avg_per_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = bear_data.join(min_avg_per_week, on = 'year_week_of_year')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['is_min'] = np.where(joined['min_weekly'] == joined['avg'], True, False)\n",
    "joined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_days_bear = joined[joined['is_min']]['day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_days_bear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Extract target (Y) and features (X)\n",
    "X = data.drop(Y,axis=1).values  # np array\n",
    "y = data[Y].values # np array\n",
    "\n",
    "# Re-shape features to be an array\n",
    "if X.ndim == 1:\n",
    "    X.reshape(-1,1) # -1 for \"figure out how many rows\", then 1 column, so N x 1 matrix\n",
    "\n",
    "# Optional - plot X vs y\n",
    "import matplotlib as plt\n",
    "plt.scatter(X,y)\n",
    "plt.ylable(\"Y label (units\")\n",
    "plt.xlable(\"X label (units)\")\n",
    "\n",
    "# Import and instantiate regression model\n",
    "from sklearn.<model_type> import RegressionModel\n",
    "\n",
    "reg = RegressionModel()\n",
    "\n",
    "# Fit model\n",
    "reg.fit(X,y)\n",
    "\n",
    "# Predict\n",
    "predicts = reg.predict(X)\n",
    "\n",
    "# Plot prediction\n",
    "plt.scatter(X,y)\n",
    "plt.plt(X,predictions)\n",
    "plt.ylable(\"Y label (units\")\n",
    "plt.xlable(\"X label (units)\")\n",
    "plt.show\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('btc-dca-eda-MSG1EnHX')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "374ad9e87d5dedfce6ec5d3d60c1d3bc9433ff49f9102c4d3e97aadd9ce87734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
